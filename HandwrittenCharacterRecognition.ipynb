{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hari1991/Edureka-PGDAIML/blob/main/HandwrittenCharacterRecognition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "db194ac8",
      "metadata": {
        "id": "db194ac8"
      },
      "source": [
        "Mid Program Project II"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Initial setup\n"
      ],
      "metadata": {
        "id": "l6Ec49lT-Zif"
      },
      "id": "l6Ec49lT-Zif"
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p images-data\n",
        "!rm -rf images-data/*\n",
        "!rm -rf words/\n",
        "!rm -rf sample_data/\n",
        "!rm -rf __MACOSX/\n",
        "!rm -rf combined.zip\n",
        "!rm -rf parser.txt\n",
        "!rm -rf text-data.zip\n",
        "\n",
        "!wget https://github.com/hari1991/Edureka-PGDAIML/raw/main/images.zip.partaa -P images-data/\n",
        "!wget https://github.com/hari1991/Edureka-PGDAIML/raw/main/images.zip.partab -P images-data/\n",
        "!wget https://github.com/hari1991/Edureka-PGDAIML/raw/main/images.zip.partac -P images-data/\n",
        "!wget https://github.com/hari1991/Edureka-PGDAIML/raw/main/images.zip.partad -P images-data/\n",
        "!wget https://github.com/hari1991/Edureka-PGDAIML/raw/main/images.zip.partae -P images-data/\n",
        "!wget https://github.com/hari1991/Edureka-PGDAIML/raw/main/images.zip.partaf -P images-data/\n",
        "!wget https://github.com/hari1991/Edureka-PGDAIML/raw/main/images.zip.partag -P images-data/\n",
        "!wget https://github.com/hari1991/Edureka-PGDAIML/raw/main/images.zip.partah -P images-data/\n",
        "!wget https://github.com/hari1991/Edureka-PGDAIML/raw/main/images.zip.partai -P images-data/\n",
        "!wget https://github.com/hari1991/Edureka-PGDAIML/raw/main/images.zip.partaj -P images-data/\n",
        "!wget https://github.com/hari1991/Edureka-PGDAIML/raw/main/images.zip.partak -P images-data/\n",
        "!wget https://github.com/hari1991/Edureka-PGDAIML/raw/main/images.zip.partal -P images-data/\n",
        "\n",
        "!cat images-data/images.zip.parta*>combined.zip\n",
        "!apt install p7zip-full\n",
        "!unzip combined.zip\n",
        "\n",
        "!wget https://github.com/hari1991/Edureka-PGDAIML/raw/main/text-data.zip\n",
        "!unzip text-data.zip\n",
        "!sed -i 's/\\r\\n//g' parser.txt\n",
        "\n"
      ],
      "metadata": {
        "id": "Znjvqq9L-coF"
      },
      "id": "Znjvqq9L-coF",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "plOg55HrokCW"
      },
      "id": "plOg55HrokCW",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "77ab5977",
      "metadata": {
        "id": "77ab5977"
      },
      "source": [
        "## 1.Read the parser.txt file containing the image id and the respective word for that image and take the first 10000 instances for training and testing of the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3f7434c0",
      "metadata": {
        "id": "3f7434c0"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import matplotlib.image as mpimg\n",
        "import matplotlib.pyplot as plt\n",
        "import string\n",
        "\n",
        "import cv2\n",
        "import os\n",
        "\n",
        "import tensorflow\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Input,Dense,Dropout,Conv2D,Flatten,MaxPool2D,Activation,Conv1D, MaxPooling1D, Bidirectional, LSTM,MaxPooling2D,Reshape,Lambda\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.models import Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "008ca6b0",
      "metadata": {
        "id": "008ca6b0"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"parser.txt\", sep=\"\\s\", on_bad_lines='skip', header=None)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "56cc292c",
      "metadata": {
        "id": "56cc292c"
      },
      "outputs": [],
      "source": [
        "train_test_dataset = df.head(10000)\n",
        "type(train_test_dataset)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eafb8aa0",
      "metadata": {
        "id": "eafb8aa0"
      },
      "outputs": [],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1d534a8f",
      "metadata": {
        "id": "1d534a8f"
      },
      "outputs": [],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "02fcc284",
      "metadata": {
        "id": "02fcc284"
      },
      "outputs": [],
      "source": [
        "img = mpimg.imread('words/a01/a01-000u/a01-000u-00-01.png')\n",
        "imgplot = plt.imshow(img)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e1908aa9",
      "metadata": {
        "id": "e1908aa9"
      },
      "outputs": [],
      "source": [
        "img.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d9f53c64",
      "metadata": {
        "id": "d9f53c64"
      },
      "outputs": [],
      "source": [
        "img.size"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p resized\n",
        "!rm -rf resized/*"
      ],
      "metadata": {
        "id": "BCX0D4Z3a1oB"
      },
      "id": "BCX0D4Z3a1oB",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_test_dataset.dtypes"
      ],
      "metadata": {
        "id": "GpkQ-VpLFB0p"
      },
      "id": "GpkQ-VpLFB0p",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Adding originalFile Path in the test data set"
      ],
      "metadata": {
        "id": "1OyaogTiHl_j"
      },
      "id": "1OyaogTiHl_j"
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "train_test_dataset[9]=train_test_dataset[0].apply(lambda x: \"words/\" \\\n",
        "                    +x.split(\"-\")[0] +\"/\"\\\n",
        "                    +x.split(\"-\")[0]+\"-\"+x.split(\"-\")[1]+\"/\"\\\n",
        "                    +x+\".png\")"
      ],
      "metadata": {
        "id": "1Adbo90axVED"
      },
      "id": "1Adbo90axVED",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Adding resized image path"
      ],
      "metadata": {
        "id": "BlplVb5aH341"
      },
      "id": "BlplVb5aH341"
    },
    {
      "cell_type": "code",
      "source": [
        "train_test_dataset[10]=train_test_dataset[0].apply(lambda x: \"resized/\" \\\n",
        "                    +x.split(\"-\")[0] +\"/\"\\\n",
        "                    +x.split(\"-\")[0]+\"-\"+x.split(\"-\")[1]+\"/\"\\\n",
        "                    +x+\".png\")"
      ],
      "metadata": {
        "id": "VluXVWQUJIKQ"
      },
      "id": "VluXVWQUJIKQ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Adding normalized image path"
      ],
      "metadata": {
        "id": "ygJwD0HQJTbw"
      },
      "id": "ygJwD0HQJTbw"
    },
    {
      "cell_type": "code",
      "source": [
        "train_test_dataset[11]=train_test_dataset[0].apply(lambda x: \"normalized/\" \\\n",
        "                    +x.split(\"-\")[0] +\"/\"\\\n",
        "                    +x.split(\"-\")[0]+\"-\"+x.split(\"-\")[1]+\"/\"\\\n",
        "                    +x+\".png\")"
      ],
      "metadata": {
        "id": "zJdqCpGdJbRB"
      },
      "id": "zJdqCpGdJbRB",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_test_dataset.head(5)"
      ],
      "metadata": {
        "id": "mzJhvildGOMh"
      },
      "id": "mzJhvildGOMh",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Images can be of different shape thus resize all your images to have the same shape (for example = (128,32))"
      ],
      "metadata": {
        "id": "G8TtctEnUg4a"
      },
      "id": "G8TtctEnUg4a"
    },
    {
      "cell_type": "code",
      "source": [
        "def distortion_free_resize(input_file_path, output_file_path, img_size=(128, 32)):\n",
        "  try:\n",
        "    w, h = img_size\n",
        "    image = tf.io.read_file(input_file_path)\n",
        "    image = tf.image.decode_png(image, 1)\n",
        "    image = tf.image.resize(image, size=(32,128), preserve_aspect_ratio=True)\n",
        "\n",
        "    # Check tha amount of padding needed to be done.\n",
        "    pad_height = h - tf.shape(image)[0]\n",
        "    pad_width = w - tf.shape(image)[1]\n",
        "\n",
        "    # Only necessary if you want to do same amount of padding on both sides.\n",
        "    if pad_height % 2 != 0:\n",
        "        height = pad_height // 2\n",
        "        pad_height_top = height + 1\n",
        "        pad_height_bottom = height\n",
        "    else:\n",
        "        pad_height_top = pad_height_bottom = pad_height // 2\n",
        "\n",
        "    if pad_width % 2 != 0:\n",
        "        width = pad_width // 2\n",
        "        pad_width_left = width + 1\n",
        "        pad_width_right = width\n",
        "    else:\n",
        "        pad_width_left = pad_width_right = pad_width // 2\n",
        "\n",
        "    image = tf.pad(\n",
        "        image,\n",
        "        paddings=[\n",
        "            [pad_height_top, pad_height_bottom],\n",
        "            [pad_width_left, pad_width_right],\n",
        "            [0, 0],\n",
        "        ],\n",
        "    )\n",
        "\n",
        "    image = tf.transpose(image, perm=[1, 0, 2])\n",
        "    image = tf.image.flip_left_right(image)\n",
        "    image = tf.image.convert_image_dtype(image, dtype=tf.uint8)\n",
        "    os.makedirs(os.path.dirname(output_file_path), exist_ok=True)\n",
        "    tf.io.write_file(output_file_path, tf.image.encode_png(image))\n",
        "  except Exception as err:\n",
        "    print(f\"Unexpected {err=}, {type(err)=} when processing {input_file_path}\")\n",
        "\n",
        "print(\"Iterating over the first 10000 records\")\n",
        "for index, row in train_test_dataset.iterrows():\n",
        "    distortion_free_resize(row[9],row[10])\n"
      ],
      "metadata": {
        "id": "9ULBy5OiijGf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d2e7a71f-1dc8-4b06-8d3a-96a66c4b8085"
      },
      "id": "9ULBy5OiijGf",
      "execution_count": 254,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iterating over the first 10000 records\n",
            "Unexpected err=InvalidArgumentError(), type(err)=<class 'tensorflow.python.framework.errors_impl.InvalidArgumentError'> when processing words/a01/a01-117/a01-117-05-02.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "img = mpimg.imread('resized/a01/a01-000u/a01-000u-00-01.png')\n",
        "imgplot = plt.imshow(img)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "hDS7TYV1jDXq"
      },
      "id": "hDS7TYV1jDXq",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Currently, the pixel values are between 0 to 255, normalize the images so that the pixel values are in range 0 to 1"
      ],
      "metadata": {
        "id": "dTiVCOoSlJkb"
      },
      "id": "dTiVCOoSlJkb"
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p normalized\n",
        "!rm -rf normalized/*"
      ],
      "metadata": {
        "id": "bVfvxd3LlvHY"
      },
      "id": "bVfvxd3LlvHY",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 256,
      "id": "19c8c9bd",
      "metadata": {
        "id": "19c8c9bd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dcef047c-cc1f-4442-de98-bf1b76793d77"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iterating over the first 10000 records\n",
            "Unexpected err=AttributeError(\"'NoneType' object has no attribute 'astype'\"), type(err)=<class 'AttributeError'> when processing resized/a01/a01-117/a01-117-05-02.png\n"
          ]
        }
      ],
      "source": [
        "def normalize_image(input_file_path, output_file_path, target_size=(128, 32)):\n",
        "    try:\n",
        "      # Create directories if not exist\n",
        "      os.makedirs(os.path.dirname(output_file_path), exist_ok=True)\n",
        "\n",
        "      # Read the image\n",
        "      image = cv2.imread(input_file_path)\n",
        "\n",
        "      # Normalize pixel values to range [0, 1]\n",
        "      normalized_image = image.astype(float) / 255.0\n",
        "\n",
        "      # Write the Normalize image to the output folder\n",
        "      cv2.imwrite(output_file_path, (normalized_image).astype(float))\n",
        "    except Exception as err:\n",
        "      print(f\"Unexpected {err=}, {type(err)=} when processing {input_file_path}\")\n",
        "\n",
        "\n",
        "print(\"Iterating over the first 10000 records\")\n",
        "for index, row in train_test_dataset.iterrows():\n",
        "    normalize_image(row[10],row[11])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "img = mpimg.imread('normalized/a01/a01-000u/a01-000u-00-01.png')\n",
        "imgplot = plt.imshow(img)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ie40iMnrm3jQ"
      },
      "id": "ie40iMnrm3jQ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Create a list of all characters and use the character’s index to encode the actual words into digits"
      ],
      "metadata": {
        "id": "Ge9lalrlrTp0"
      },
      "id": "Ge9lalrlrTp0"
    },
    {
      "cell_type": "code",
      "execution_count": 258,
      "metadata": {
        "id": "31fc2a93",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8b5485a8-479e-48e5-852e-4eac715022b9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[' ', '!', '\"', '#', '$', '%', '&', \"'\", '(', ')', '*', '+', ',', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '<', '=', '>', '?', '@', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', '[', '\\\\', ']', '^', '_', '`', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '{', '|', '}', '~'] 95\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-258-a7aa171d0e5c>:11: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  train_test_dataset[12]=train_test_dataset[8].apply(encode_with_index)\n"
          ]
        }
      ],
      "source": [
        "characters=[chr(i) for i in range(32, 127)]\n",
        "print(characters,len(characters))\n",
        "\n",
        "def encode_with_index(x):\n",
        "  try:\n",
        "    return [characters.index(char) for char in x]\n",
        "  except Exception as e:\n",
        "    print(f\"Unexpected error while encoding {x}\")\n",
        "    return []\n",
        "\n",
        "train_test_dataset[12]=train_test_dataset[8].apply(encode_with_index)"
      ],
      "id": "31fc2a93"
    },
    {
      "cell_type": "code",
      "source": [
        "train_test_dataset[[8,12]].head(3)"
      ],
      "metadata": {
        "id": "Y2xtlX-lacWk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "outputId": "aa04451b-0cc3-4877-d3f9-a5909ea1f575"
      },
      "execution_count": 259,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     8                 12\n",
              "0     A              [33]\n",
              "1  MOVE  [45, 47, 54, 37]\n",
              "2    to          [84, 79]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-cf6bc0cd-8408-4158-a269-eb808566edcb\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>8</th>\n",
              "      <th>12</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>A</td>\n",
              "      <td>[33]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>MOVE</td>\n",
              "      <td>[45, 47, 54, 37]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>to</td>\n",
              "      <td>[84, 79]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cf6bc0cd-8408-4158-a269-eb808566edcb')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-cf6bc0cd-8408-4158-a269-eb808566edcb button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-cf6bc0cd-8408-4158-a269-eb808566edcb');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-eb11167d-0043-4db7-b58e-50530d28131c\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-eb11167d-0043-4db7-b58e-50530d28131c')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-eb11167d-0043-4db7-b58e-50530d28131c button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"train_test_dataset[[8,12]]\",\n  \"rows\": 3,\n  \"fields\": [\n    {\n      \"column\": 8,\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"A\",\n          \"MOVE\",\n          \"to\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 12,\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 259
        }
      ],
      "id": "Y2xtlX-lacWk"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Pad all the words to have a similar length"
      ],
      "metadata": {
        "id": "S8D5NPvjRzc0"
      },
      "id": "S8D5NPvjRzc0"
    },
    {
      "cell_type": "code",
      "source": [
        "max_length_with_padding = train_test_dataset[8].str.len().max()\n",
        "print(\"Max length for padding\",max_length_with_padding)\n",
        "\n",
        "train_test_dataset[13]=pad_sequences(train_test_dataset[12], maxlen=max_length_with_padding, padding='post').tolist()"
      ],
      "metadata": {
        "id": "U0KSsNaiR49t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1769ce80-f847-40fa-8b76-b0a5030b336b"
      },
      "id": "U0KSsNaiR49t",
      "execution_count": 260,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Max length for padding 18\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-260-9d0ecdea048f>:4: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  train_test_dataset[13]=pad_sequences(train_test_dataset[12], maxlen=max_length_with_padding, padding='post').tolist()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "83b6399c",
      "metadata": {
        "id": "83b6399c"
      },
      "outputs": [],
      "source": [
        "train_test_dataset[[8,12,13]].head(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Split your dataset for training and testing"
      ],
      "metadata": {
        "id": "BcfU182QcMDm"
      },
      "id": "BcfU182QcMDm"
    },
    {
      "cell_type": "code",
      "execution_count": 261,
      "id": "fd6a9c34",
      "metadata": {
        "id": "fd6a9c34",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a16e62f5-29a8-46c9-862a-cd64a2ea4e36"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set : 8000 8000\n",
            "Testing set: 2000 2000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-261-5a6e0c51c4c8>:5: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  train_test_dataset[14]=train_test_dataset[11].apply(lambda x: cv2.imread(x))\n"
          ]
        }
      ],
      "source": [
        "#from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Assuming df contains your DataFrame with 'Padded_Text' and other columns\n",
        "# X contains features and y contains labels (if available)\n",
        "train_test_dataset[14]=train_test_dataset[11].apply(lambda x: cv2.imread(x))\n",
        "X = train_test_dataset[14].to_list()\n",
        "y = train_test_dataset[8].to_list()  # Replace 'label_column' with the actual label column name\n",
        "\n",
        "# Split the dataset into training and testing sets (80% train, 20% test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Print the shapes of the split datasets\n",
        "print(\"Training set :\", len(X_train), len(y_train))\n",
        "print(\"Testing set:\", len(X_test), len(y_test))\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7. Create a model for training:\n",
        "\n",
        "\n",
        "1.   Add several CNN layers to extract the sequence of features\n",
        "2.   Add Bi-LSTM layers to propagate through the sequence\n",
        "3.   Add a dense layer (output layer) with total number of neurons as (total number of characters + 1) and the activation as softmax."
      ],
      "metadata": {
        "id": "UlBWkDLNckt5"
      },
      "id": "UlBWkDLNckt5"
    },
    {
      "cell_type": "code",
      "execution_count": 263,
      "id": "3125b2f8",
      "metadata": {
        "id": "3125b2f8"
      },
      "outputs": [],
      "source": [
        "# Assuming max_length is the maximum length of your padded sequences\n",
        "max_length = len(X_train[0])\n",
        "\n",
        "# Number of unique characters + 1 for padding\n",
        "num_classes = len(characters) + 1\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Defining CNN layers\n",
        "def define_cnn_layers(inputs):\n",
        "    # Convolutional layers\n",
        "    x = Conv2D(32, kernel_size=(3, 3), activation='relu', padding='same')(inputs)\n",
        "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
        "    x = Conv2D(64, kernel_size=(3, 3), activation='relu', padding='same')(x)\n",
        "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
        "    #Reshaping necessary\n",
        "    new_shape = ((128 // 4), (32 // 4) * 64)\n",
        "    x = Reshape(target_shape=new_shape, name=\"reshape\")(x)\n",
        "    x = Dense(64, activation=\"relu\", name=\"dense1\")(x)\n",
        "    x = Dropout(0.2)(x)\n",
        "    return x\n",
        "\n",
        "# DefiningBidirectional LSTM layers\n",
        "def define_bidirectional_lstm_layers(inputs):\n",
        "    x = Bidirectional(LSTM(128, return_sequences=True, dropout=0.25))(inputs)\n",
        "    x = keras.layers.Bidirectional(keras.layers.LSTM(64, return_sequences=True, dropout=0.25))(x)\n",
        "    return x\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 8. The output sequence from the output layer will be fed to the CTC layer."
      ],
      "metadata": {
        "id": "aPMQGmMuc9ik"
      },
      "id": "aPMQGmMuc9ik"
    },
    {
      "cell_type": "code",
      "execution_count": 264,
      "id": "2bbb4367",
      "metadata": {
        "id": "2bbb4367",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "157dde04-1afe-41cb-daf9-c5be2ed3ffcd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"handwriting_recognizer\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_11 (InputLayer)       [(None, 128, 32, 1)]         0         []                            \n",
            "                                                                                                  \n",
            " conv2d_33 (Conv2D)          (None, 128, 32, 32)          320       ['input_11[0][0]']            \n",
            "                                                                                                  \n",
            " max_pooling2d_32 (MaxPooli  (None, 64, 16, 32)           0         ['conv2d_33[0][0]']           \n",
            " ng2D)                                                                                            \n",
            "                                                                                                  \n",
            " conv2d_34 (Conv2D)          (None, 64, 16, 64)           18496     ['max_pooling2d_32[0][0]']    \n",
            "                                                                                                  \n",
            " max_pooling2d_33 (MaxPooli  (None, 32, 8, 64)            0         ['conv2d_34[0][0]']           \n",
            " ng2D)                                                                                            \n",
            "                                                                                                  \n",
            " reshape (Reshape)           (None, 32, 512)              0         ['max_pooling2d_33[0][0]']    \n",
            "                                                                                                  \n",
            " dense1 (Dense)              (None, 32, 64)               32832     ['reshape[0][0]']             \n",
            "                                                                                                  \n",
            " dropout_4 (Dropout)         (None, 32, 64)               0         ['dense1[0][0]']              \n",
            "                                                                                                  \n",
            " bidirectional_18 (Bidirect  (None, 32, 256)              197632    ['dropout_4[0][0]']           \n",
            " ional)                                                                                           \n",
            "                                                                                                  \n",
            " bidirectional_19 (Bidirect  (None, 32, 128)              164352    ['bidirectional_18[0][0]']    \n",
            " ional)                                                                                           \n",
            "                                                                                                  \n",
            " the_labels (InputLayer)     [(None, None)]               0         []                            \n",
            "                                                                                                  \n",
            " dense_4 (Dense)             (None, 32, 97)               12513     ['bidirectional_19[0][0]']    \n",
            "                                                                                                  \n",
            " ctc_loss (CTCLayer)         (None, 32, 97)               0         ['the_labels[0][0]',          \n",
            "                                                                     'dense_4[0][0]']             \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 426145 (1.63 MB)\n",
            "Trainable params: 426145 (1.63 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "class CTCLayer(keras.layers.Layer):\n",
        "    def __init__(self, name=None):\n",
        "        super().__init__(name=name)\n",
        "        self.loss_fn = keras.backend.ctc_batch_cost\n",
        "\n",
        "    def call(self, y_true, y_pred):\n",
        "        batch_len = tf.cast(tf.shape(y_true)[0], dtype=\"int64\")\n",
        "        input_length = tf.cast(tf.shape(y_pred)[1], dtype=\"int64\")\n",
        "        label_length = tf.cast(tf.shape(y_true)[1], dtype=\"int64\")\n",
        "\n",
        "        input_length = input_length * tf.ones(shape=(batch_len, 1), dtype=\"int64\")\n",
        "        label_length = label_length * tf.ones(shape=(batch_len, 1), dtype=\"int64\")\n",
        "        loss = self.loss_fn(y_true, y_pred, input_length, label_length)\n",
        "        self.add_loss(loss)\n",
        "\n",
        "        # At test time, just return the computed predictions.\n",
        "        return y_pred\n",
        "\n",
        "\n",
        "# Define your model architecture\n",
        "inputs = Input(shape=(128, 32, 1))\n",
        "cnn_output = define_cnn_layers(inputs)\n",
        "lstm_output = define_bidirectional_lstm_layers(cnn_output)\n",
        "dense_output = Dense(num_classes+1, activation='softmax')(lstm_output)\n",
        "\n",
        "# Define input labels and lengths\n",
        "the_labels = Input(name='the_labels', shape=[None], dtype='float32')\n",
        "\n",
        "\n",
        "# Add CTC layer for calculating CTC loss at each step.\n",
        "output = CTCLayer(name=\"ctc_loss\")(the_labels, dense_output)\n",
        "\n",
        "# Define the model.\n",
        "model = Model(\n",
        "    inputs=[inputs, the_labels], outputs=output, name=\"handwriting_recognizer\"\n",
        ")\n",
        "# Optimizer.\n",
        "opt = keras.optimizers.Adam()\n",
        "# Compile the model and return.\n",
        "model.compile(optimizer=opt)\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 9. Predict output using your model (don’t use the last loss layer) on validation images, use ctc_decode to decode your output and then print the actual words using the indexes from your character’s list."
      ],
      "metadata": {
        "id": "8M9nIiefdJpc"
      },
      "id": "8M9nIiefdJpc"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bcc58d3c",
      "metadata": {
        "id": "bcc58d3c"
      },
      "outputs": [],
      "source": [
        "batch_size = 32\n",
        "def prepare_dataset(image_paths, labels):\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((image_paths, labels))\n",
        "    return dataset.batch(batch_size).cache().prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "train_dataset = prepare_dataset(X_train,y_train)\n",
        "\n",
        "validation_dataset = prepare_dataset(X_test,y_test)\n",
        "\n",
        "# Train model\n",
        "model.fit(train_dataset, epochs=30, batch_size=32, validation_data=validation_dataset)\n",
        "\n",
        "# Evaluate model\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(\"Test Loss:\", loss)\n",
        "print(\"Test Accuracy:\", accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8166495b",
      "metadata": {
        "id": "8166495b"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6be5a8f7",
      "metadata": {
        "id": "6be5a8f7"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8a4d2130",
      "metadata": {
        "id": "8a4d2130"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fd8d5105",
      "metadata": {
        "id": "fd8d5105"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.5"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}