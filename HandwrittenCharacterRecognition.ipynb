{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hari1991/Edureka-PGDAIML/blob/main/HandwrittenCharacterRecognition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "db194ac8",
      "metadata": {
        "id": "db194ac8"
      },
      "source": [
        "Mid Program Project II"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Initial setup\n"
      ],
      "metadata": {
        "id": "l6Ec49lT-Zif"
      },
      "id": "l6Ec49lT-Zif"
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p images-data\n",
        "!rm -rf images-data/*\n",
        "!rm -rf words/\n",
        "!rm -rf sample_data/\n",
        "!rm -rf __MACOSX/\n",
        "!rm -rf combined.zip\n",
        "!rm -rf parser.txt\n",
        "!rm -rf text-data.zip\n",
        "\n",
        "!wget https://github.com/hari1991/Edureka-PGDAIML/raw/main/images.zip.partaa -P images-data/\n",
        "!wget https://github.com/hari1991/Edureka-PGDAIML/raw/main/images.zip.partab -P images-data/\n",
        "!wget https://github.com/hari1991/Edureka-PGDAIML/raw/main/images.zip.partac -P images-data/\n",
        "!wget https://github.com/hari1991/Edureka-PGDAIML/raw/main/images.zip.partad -P images-data/\n",
        "!wget https://github.com/hari1991/Edureka-PGDAIML/raw/main/images.zip.partae -P images-data/\n",
        "!wget https://github.com/hari1991/Edureka-PGDAIML/raw/main/images.zip.partaf -P images-data/\n",
        "!wget https://github.com/hari1991/Edureka-PGDAIML/raw/main/images.zip.partag -P images-data/\n",
        "!wget https://github.com/hari1991/Edureka-PGDAIML/raw/main/images.zip.partah -P images-data/\n",
        "!wget https://github.com/hari1991/Edureka-PGDAIML/raw/main/images.zip.partai -P images-data/\n",
        "!wget https://github.com/hari1991/Edureka-PGDAIML/raw/main/images.zip.partaj -P images-data/\n",
        "!wget https://github.com/hari1991/Edureka-PGDAIML/raw/main/images.zip.partak -P images-data/\n",
        "!wget https://github.com/hari1991/Edureka-PGDAIML/raw/main/images.zip.partal -P images-data/\n",
        "\n",
        "!cat images-data/images.zip.parta*>combined.zip\n",
        "!apt install p7zip-full\n",
        "!unzip combined.zip\n",
        "\n",
        "!wget https://github.com/hari1991/Edureka-PGDAIML/raw/main/text-data.zip\n",
        "!unzip text-data.zip\n",
        "!sed -i 's/\\r\\n//g' parser.txt\n",
        "\n"
      ],
      "metadata": {
        "id": "Znjvqq9L-coF"
      },
      "id": "Znjvqq9L-coF",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "plOg55HrokCW"
      },
      "id": "plOg55HrokCW",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "77ab5977",
      "metadata": {
        "id": "77ab5977"
      },
      "source": [
        "## 1.Read the parser.txt file containing the image id and the respective word for that image and take the first 10000 instances for training and testing of the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3f7434c0",
      "metadata": {
        "id": "3f7434c0"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import matplotlib.image as mpimg\n",
        "import matplotlib.pyplot as plt\n",
        "import string\n",
        "\n",
        "import cv2\n",
        "import os\n",
        "\n",
        "import tensorflow\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Input,Dense,Dropout,Conv2D,Flatten,MaxPool2D,Activation,Conv1D, MaxPooling1D, Bidirectional, LSTM,MaxPooling2D,Reshape,Lambda\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.models import Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "008ca6b0",
      "metadata": {
        "id": "008ca6b0"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"parser.txt\", sep=\"\\s\", on_bad_lines='skip', header=None)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "56cc292c",
      "metadata": {
        "id": "56cc292c"
      },
      "outputs": [],
      "source": [
        "train_test_dataset = df.head(10000)\n",
        "type(train_test_dataset)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eafb8aa0",
      "metadata": {
        "id": "eafb8aa0"
      },
      "outputs": [],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1d534a8f",
      "metadata": {
        "id": "1d534a8f"
      },
      "outputs": [],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "02fcc284",
      "metadata": {
        "id": "02fcc284"
      },
      "outputs": [],
      "source": [
        "img = mpimg.imread('words/a01/a01-000u/a01-000u-00-01.png')\n",
        "imgplot = plt.imshow(img)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e1908aa9",
      "metadata": {
        "id": "e1908aa9"
      },
      "outputs": [],
      "source": [
        "img.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d9f53c64",
      "metadata": {
        "id": "d9f53c64"
      },
      "outputs": [],
      "source": [
        "img.size"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p resized\n",
        "!rm -rf resized/*"
      ],
      "metadata": {
        "id": "BCX0D4Z3a1oB"
      },
      "id": "BCX0D4Z3a1oB",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_test_dataset.dtypes"
      ],
      "metadata": {
        "id": "GpkQ-VpLFB0p"
      },
      "id": "GpkQ-VpLFB0p",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Adding originalFile Path in the test data set"
      ],
      "metadata": {
        "id": "1OyaogTiHl_j"
      },
      "id": "1OyaogTiHl_j"
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "train_test_dataset[9]=train_test_dataset[0].apply(lambda x: \"words/\" \\\n",
        "                    +x.split(\"-\")[0] +\"/\"\\\n",
        "                    +x.split(\"-\")[0]+\"-\"+x.split(\"-\")[1]+\"/\"\\\n",
        "                    +x+\".png\")"
      ],
      "metadata": {
        "id": "1Adbo90axVED"
      },
      "id": "1Adbo90axVED",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Adding resized image path"
      ],
      "metadata": {
        "id": "BlplVb5aH341"
      },
      "id": "BlplVb5aH341"
    },
    {
      "cell_type": "code",
      "source": [
        "train_test_dataset[10]=train_test_dataset[0].apply(lambda x: \"resized/\" \\\n",
        "                    +x.split(\"-\")[0] +\"/\"\\\n",
        "                    +x.split(\"-\")[0]+\"-\"+x.split(\"-\")[1]+\"/\"\\\n",
        "                    +x+\".png\")"
      ],
      "metadata": {
        "id": "VluXVWQUJIKQ"
      },
      "id": "VluXVWQUJIKQ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Adding normalized image path"
      ],
      "metadata": {
        "id": "ygJwD0HQJTbw"
      },
      "id": "ygJwD0HQJTbw"
    },
    {
      "cell_type": "code",
      "source": [
        "train_test_dataset[11]=train_test_dataset[0].apply(lambda x: \"normalized/\" \\\n",
        "                    +x.split(\"-\")[0] +\"/\"\\\n",
        "                    +x.split(\"-\")[0]+\"-\"+x.split(\"-\")[1]+\"/\"\\\n",
        "                    +x+\".png\")"
      ],
      "metadata": {
        "id": "zJdqCpGdJbRB"
      },
      "id": "zJdqCpGdJbRB",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_test_dataset.head(5)"
      ],
      "metadata": {
        "id": "mzJhvildGOMh"
      },
      "id": "mzJhvildGOMh",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Images can be of different shape thus resize all your images to have the same shape (for example = (128,32))"
      ],
      "metadata": {
        "id": "G8TtctEnUg4a"
      },
      "id": "G8TtctEnUg4a"
    },
    {
      "cell_type": "code",
      "source": [
        "def distortion_free_resize(input_file_path, output_file_path, img_size=(128, 32)):\n",
        "  try:\n",
        "    w, h = img_size\n",
        "    image = tf.io.read_file(input_file_path)\n",
        "    image = tf.image.decode_png(image, 1)\n",
        "    image = tf.image.resize(image, size=(32,128), preserve_aspect_ratio=True)\n",
        "\n",
        "    # Check tha amount of padding needed to be done.\n",
        "    pad_height = h - tf.shape(image)[0]\n",
        "    pad_width = w - tf.shape(image)[1]\n",
        "\n",
        "    # Only necessary if you want to do same amount of padding on both sides.\n",
        "    if pad_height % 2 != 0:\n",
        "        height = pad_height // 2\n",
        "        pad_height_top = height + 1\n",
        "        pad_height_bottom = height\n",
        "    else:\n",
        "        pad_height_top = pad_height_bottom = pad_height // 2\n",
        "\n",
        "    if pad_width % 2 != 0:\n",
        "        width = pad_width // 2\n",
        "        pad_width_left = width + 1\n",
        "        pad_width_right = width\n",
        "    else:\n",
        "        pad_width_left = pad_width_right = pad_width // 2\n",
        "\n",
        "    image = tf.pad(\n",
        "        image,\n",
        "        paddings=[\n",
        "            [pad_height_top, pad_height_bottom],\n",
        "            [pad_width_left, pad_width_right],\n",
        "            [0, 0],\n",
        "        ],\n",
        "    )\n",
        "\n",
        "    image = tf.transpose(image, perm=[1, 0, 2])\n",
        "    image = tf.image.flip_left_right(image)\n",
        "    image = tf.image.convert_image_dtype(image, dtype=tf.uint8)\n",
        "    os.makedirs(os.path.dirname(output_file_path), exist_ok=True)\n",
        "    tf.io.write_file(output_file_path, tf.image.encode_png(image))\n",
        "  except Exception as err:\n",
        "    print(f\"Unexpected {err=}, {type(err)=} when processing {input_file_path}\")\n",
        "\n",
        "print(\"Iterating over the first 10000 records\")\n",
        "for index, row in train_test_dataset.iterrows():\n",
        "    distortion_free_resize(row[9],row[10])\n"
      ],
      "metadata": {
        "id": "9ULBy5OiijGf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d2e7a71f-1dc8-4b06-8d3a-96a66c4b8085"
      },
      "id": "9ULBy5OiijGf",
      "execution_count": 254,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iterating over the first 10000 records\n",
            "Unexpected err=InvalidArgumentError(), type(err)=<class 'tensorflow.python.framework.errors_impl.InvalidArgumentError'> when processing words/a01/a01-117/a01-117-05-02.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "img = mpimg.imread('resized/a01/a01-000u/a01-000u-00-01.png')\n",
        "imgplot = plt.imshow(img)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "hDS7TYV1jDXq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 434
        },
        "outputId": "97ec7618-b1f5-4be7-a102-185d8da0ddb9"
      },
      "id": "hDS7TYV1jDXq",
      "execution_count": 255,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Currently, the pixel values are between 0 to 255, normalize the images so that the pixel values are in range 0 to 1"
      ],
      "metadata": {
        "id": "dTiVCOoSlJkb"
      },
      "id": "dTiVCOoSlJkb"
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p normalized\n",
        "!rm -rf normalized/*"
      ],
      "metadata": {
        "id": "bVfvxd3LlvHY"
      },
      "id": "bVfvxd3LlvHY",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 256,
      "id": "19c8c9bd",
      "metadata": {
        "id": "19c8c9bd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dcef047c-cc1f-4442-de98-bf1b76793d77"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iterating over the first 10000 records\n",
            "Unexpected err=AttributeError(\"'NoneType' object has no attribute 'astype'\"), type(err)=<class 'AttributeError'> when processing resized/a01/a01-117/a01-117-05-02.png\n"
          ]
        }
      ],
      "source": [
        "def normalize_image(input_file_path, output_file_path, target_size=(128, 32)):\n",
        "    try:\n",
        "      # Create directories if not exist\n",
        "      os.makedirs(os.path.dirname(output_file_path), exist_ok=True)\n",
        "\n",
        "      # Read the image\n",
        "      image = cv2.imread(input_file_path)\n",
        "\n",
        "      # Normalize pixel values to range [0, 1]\n",
        "      normalized_image = image.astype(float) / 255.0\n",
        "\n",
        "      # Write the Normalize image to the output folder\n",
        "      cv2.imwrite(output_file_path, (normalized_image).astype(float))\n",
        "    except Exception as err:\n",
        "      print(f\"Unexpected {err=}, {type(err)=} when processing {input_file_path}\")\n",
        "\n",
        "\n",
        "print(\"Iterating over the first 10000 records\")\n",
        "for index, row in train_test_dataset.iterrows():\n",
        "    normalize_image(row[10],row[11])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "img = mpimg.imread('normalized/a01/a01-000u/a01-000u-00-01.png')\n",
        "imgplot = plt.imshow(img)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ie40iMnrm3jQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 434
        },
        "outputId": "19f274e4-39c2-4d92-ceb7-ce7092921496"
      },
      "id": "ie40iMnrm3jQ",
      "execution_count": 257,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Create a list of all characters and use the character’s index to encode the actual words into digits"
      ],
      "metadata": {
        "id": "Ge9lalrlrTp0"
      },
      "id": "Ge9lalrlrTp0"
    },
    {
      "cell_type": "code",
      "execution_count": 258,
      "metadata": {
        "id": "31fc2a93",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8b5485a8-479e-48e5-852e-4eac715022b9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[' ', '!', '\"', '#', '$', '%', '&', \"'\", '(', ')', '*', '+', ',', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '<', '=', '>', '?', '@', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', '[', '\\\\', ']', '^', '_', '`', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '{', '|', '}', '~'] 95\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-258-a7aa171d0e5c>:11: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  train_test_dataset[12]=train_test_dataset[8].apply(encode_with_index)\n"
          ]
        }
      ],
      "source": [
        "characters=[chr(i) for i in range(32, 127)]\n",
        "print(characters,len(characters))\n",
        "\n",
        "def encode_with_index(x):\n",
        "  try:\n",
        "    return [characters.index(char) for char in x]\n",
        "  except Exception as e:\n",
        "    print(f\"Unexpected error while encoding {x}\")\n",
        "    return []\n",
        "\n",
        "train_test_dataset[12]=train_test_dataset[8].apply(encode_with_index)"
      ],
      "id": "31fc2a93"
    },
    {
      "cell_type": "code",
      "source": [
        "train_test_dataset[[8,12]].head(3)"
      ],
      "metadata": {
        "id": "Y2xtlX-lacWk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "outputId": "aa04451b-0cc3-4877-d3f9-a5909ea1f575"
      },
      "execution_count": 259,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     8                 12\n",
              "0     A              [33]\n",
              "1  MOVE  [45, 47, 54, 37]\n",
              "2    to          [84, 79]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-cf6bc0cd-8408-4158-a269-eb808566edcb\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>8</th>\n",
              "      <th>12</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>A</td>\n",
              "      <td>[33]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>MOVE</td>\n",
              "      <td>[45, 47, 54, 37]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>to</td>\n",
              "      <td>[84, 79]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cf6bc0cd-8408-4158-a269-eb808566edcb')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-cf6bc0cd-8408-4158-a269-eb808566edcb button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-cf6bc0cd-8408-4158-a269-eb808566edcb');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-eb11167d-0043-4db7-b58e-50530d28131c\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-eb11167d-0043-4db7-b58e-50530d28131c')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-eb11167d-0043-4db7-b58e-50530d28131c button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"train_test_dataset[[8,12]]\",\n  \"rows\": 3,\n  \"fields\": [\n    {\n      \"column\": 8,\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"A\",\n          \"MOVE\",\n          \"to\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 12,\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 259
        }
      ],
      "id": "Y2xtlX-lacWk"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Pad all the words to have a similar length"
      ],
      "metadata": {
        "id": "S8D5NPvjRzc0"
      },
      "id": "S8D5NPvjRzc0"
    },
    {
      "cell_type": "code",
      "source": [
        "max_length_with_padding = train_test_dataset[8].str.len().max()\n",
        "print(\"Max length for padding\",max_length_with_padding)\n",
        "\n",
        "train_test_dataset[13]=pad_sequences(train_test_dataset[12], maxlen=max_length_with_padding, padding='post').tolist()"
      ],
      "metadata": {
        "id": "U0KSsNaiR49t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1769ce80-f847-40fa-8b76-b0a5030b336b"
      },
      "id": "U0KSsNaiR49t",
      "execution_count": 260,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Max length for padding 18\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-260-9d0ecdea048f>:4: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  train_test_dataset[13]=pad_sequences(train_test_dataset[12], maxlen=max_length_with_padding, padding='post').tolist()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "83b6399c",
      "metadata": {
        "id": "83b6399c"
      },
      "outputs": [],
      "source": [
        "train_test_dataset[[8,12,13]].head(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Split your dataset for training and testing"
      ],
      "metadata": {
        "id": "BcfU182QcMDm"
      },
      "id": "BcfU182QcMDm"
    },
    {
      "cell_type": "code",
      "execution_count": 261,
      "id": "fd6a9c34",
      "metadata": {
        "id": "fd6a9c34",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a16e62f5-29a8-46c9-862a-cd64a2ea4e36"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set : 8000 8000\n",
            "Testing set: 2000 2000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-261-5a6e0c51c4c8>:5: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  train_test_dataset[14]=train_test_dataset[11].apply(lambda x: cv2.imread(x))\n"
          ]
        }
      ],
      "source": [
        "#from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Assuming df contains your DataFrame with 'Padded_Text' and other columns\n",
        "# X contains features and y contains labels (if available)\n",
        "train_test_dataset[14]=train_test_dataset[11].apply(lambda x: cv2.imread(x))\n",
        "X = train_test_dataset[14].to_list()\n",
        "y = train_test_dataset[8].to_list()  # Replace 'label_column' with the actual label column name\n",
        "\n",
        "# Split the dataset into training and testing sets (80% train, 20% test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Print the shapes of the split datasets\n",
        "print(\"Training set :\", len(X_train), len(y_train))\n",
        "print(\"Testing set:\", len(X_test), len(y_test))\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7. Create a model for training:\n",
        "\n",
        "\n",
        "1.   Add several CNN layers to extract the sequence of features\n",
        "2.   Add Bi-LSTM layers to propagate through the sequence\n",
        "3.   Add a dense layer (output layer) with total number of neurons as (total number of characters + 1) and the activation as softmax."
      ],
      "metadata": {
        "id": "UlBWkDLNckt5"
      },
      "id": "UlBWkDLNckt5"
    },
    {
      "cell_type": "code",
      "execution_count": 263,
      "id": "3125b2f8",
      "metadata": {
        "id": "3125b2f8"
      },
      "outputs": [],
      "source": [
        "# Assuming max_length is the maximum length of your padded sequences\n",
        "max_length = len(X_train[0])\n",
        "\n",
        "# Number of unique characters + 1 for padding\n",
        "num_classes = len(characters) + 1\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Defining CNN layers\n",
        "def define_cnn_layers(inputs):\n",
        "    # Convolutional layers\n",
        "    x = Conv2D(32, kernel_size=(3, 3), activation='relu', padding='same')(inputs)\n",
        "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
        "    x = Conv2D(64, kernel_size=(3, 3), activation='relu', padding='same')(x)\n",
        "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
        "    #Reshaping necessary\n",
        "    new_shape = ((128 // 4), (32 // 4) * 64)\n",
        "    x = Reshape(target_shape=new_shape, name=\"reshape\")(x)\n",
        "    x = Dense(64, activation=\"relu\", name=\"dense1\")(x)\n",
        "    x = Dropout(0.2)(x)\n",
        "    return x\n",
        "\n",
        "# DefiningBidirectional LSTM layers\n",
        "def define_bidirectional_lstm_layers(inputs):\n",
        "    x = Bidirectional(LSTM(128, return_sequences=True, dropout=0.25))(inputs)\n",
        "    x = keras.layers.Bidirectional(keras.layers.LSTM(64, return_sequences=True, dropout=0.25))(x)\n",
        "    return x\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 8. The output sequence from the output layer will be fed to the CTC layer."
      ],
      "metadata": {
        "id": "aPMQGmMuc9ik"
      },
      "id": "aPMQGmMuc9ik"
    },
    {
      "cell_type": "code",
      "execution_count": 264,
      "id": "2bbb4367",
      "metadata": {
        "id": "2bbb4367",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "157dde04-1afe-41cb-daf9-c5be2ed3ffcd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"handwriting_recognizer\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_11 (InputLayer)       [(None, 128, 32, 1)]         0         []                            \n",
            "                                                                                                  \n",
            " conv2d_33 (Conv2D)          (None, 128, 32, 32)          320       ['input_11[0][0]']            \n",
            "                                                                                                  \n",
            " max_pooling2d_32 (MaxPooli  (None, 64, 16, 32)           0         ['conv2d_33[0][0]']           \n",
            " ng2D)                                                                                            \n",
            "                                                                                                  \n",
            " conv2d_34 (Conv2D)          (None, 64, 16, 64)           18496     ['max_pooling2d_32[0][0]']    \n",
            "                                                                                                  \n",
            " max_pooling2d_33 (MaxPooli  (None, 32, 8, 64)            0         ['conv2d_34[0][0]']           \n",
            " ng2D)                                                                                            \n",
            "                                                                                                  \n",
            " reshape (Reshape)           (None, 32, 512)              0         ['max_pooling2d_33[0][0]']    \n",
            "                                                                                                  \n",
            " dense1 (Dense)              (None, 32, 64)               32832     ['reshape[0][0]']             \n",
            "                                                                                                  \n",
            " dropout_4 (Dropout)         (None, 32, 64)               0         ['dense1[0][0]']              \n",
            "                                                                                                  \n",
            " bidirectional_18 (Bidirect  (None, 32, 256)              197632    ['dropout_4[0][0]']           \n",
            " ional)                                                                                           \n",
            "                                                                                                  \n",
            " bidirectional_19 (Bidirect  (None, 32, 128)              164352    ['bidirectional_18[0][0]']    \n",
            " ional)                                                                                           \n",
            "                                                                                                  \n",
            " the_labels (InputLayer)     [(None, None)]               0         []                            \n",
            "                                                                                                  \n",
            " dense_4 (Dense)             (None, 32, 97)               12513     ['bidirectional_19[0][0]']    \n",
            "                                                                                                  \n",
            " ctc_loss (CTCLayer)         (None, 32, 97)               0         ['the_labels[0][0]',          \n",
            "                                                                     'dense_4[0][0]']             \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 426145 (1.63 MB)\n",
            "Trainable params: 426145 (1.63 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "class CTCLayer(keras.layers.Layer):\n",
        "    def __init__(self, name=None):\n",
        "        super().__init__(name=name)\n",
        "        self.loss_fn = keras.backend.ctc_batch_cost\n",
        "\n",
        "    def call(self, y_true, y_pred):\n",
        "        batch_len = tf.cast(tf.shape(y_true)[0], dtype=\"int64\")\n",
        "        input_length = tf.cast(tf.shape(y_pred)[1], dtype=\"int64\")\n",
        "        label_length = tf.cast(tf.shape(y_true)[1], dtype=\"int64\")\n",
        "\n",
        "        input_length = input_length * tf.ones(shape=(batch_len, 1), dtype=\"int64\")\n",
        "        label_length = label_length * tf.ones(shape=(batch_len, 1), dtype=\"int64\")\n",
        "        loss = self.loss_fn(y_true, y_pred, input_length, label_length)\n",
        "        self.add_loss(loss)\n",
        "\n",
        "        # At test time, just return the computed predictions.\n",
        "        return y_pred\n",
        "\n",
        "\n",
        "# Define your model architecture\n",
        "inputs = Input(shape=(128, 32, 1))\n",
        "cnn_output = define_cnn_layers(inputs)\n",
        "lstm_output = define_bidirectional_lstm_layers(cnn_output)\n",
        "dense_output = Dense(num_classes+1, activation='softmax')(lstm_output)\n",
        "\n",
        "# Define input labels and lengths\n",
        "the_labels = Input(name='the_labels', shape=[None], dtype='float32')\n",
        "\n",
        "\n",
        "# Add CTC layer for calculating CTC loss at each step.\n",
        "output = CTCLayer(name=\"ctc_loss\")(the_labels, dense_output)\n",
        "\n",
        "# Define the model.\n",
        "model = Model(\n",
        "    inputs=[inputs, the_labels], outputs=output, name=\"handwriting_recognizer\"\n",
        ")\n",
        "# Optimizer.\n",
        "opt = keras.optimizers.Adam()\n",
        "# Compile the model and return.\n",
        "model.compile(optimizer=opt)\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 9. Predict output using your model (don’t use the last loss layer) on validation images, use ctc_decode to decode your output and then print the actual words using the indexes from your character’s list."
      ],
      "metadata": {
        "id": "8M9nIiefdJpc"
      },
      "id": "8M9nIiefdJpc"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bcc58d3c",
      "metadata": {
        "id": "bcc58d3c"
      },
      "outputs": [],
      "source": [
        "batch_size = 32\n",
        "def prepare_dataset(image_paths, labels):\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((image_paths, labels))\n",
        "    return dataset.batch(batch_size).cache().prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "train_dataset = prepare_dataset(X_train,y_train)\n",
        "\n",
        "validation_dataset = prepare_dataset(X_test,y_test)\n",
        "\n",
        "# Train model\n",
        "model.fit(train_dataset, epochs=30, batch_size=32, validation_data=validation_dataset)\n",
        "\n",
        "# Evaluate model\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(\"Test Loss:\", loss)\n",
        "print(\"Test Accuracy:\", accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8166495b",
      "metadata": {
        "id": "8166495b"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6be5a8f7",
      "metadata": {
        "id": "6be5a8f7"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8a4d2130",
      "metadata": {
        "id": "8a4d2130"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fd8d5105",
      "metadata": {
        "id": "fd8d5105"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.5"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}